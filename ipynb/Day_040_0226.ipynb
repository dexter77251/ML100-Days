{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間\n",
    "試著使用 sklearn datasets 的其他資料集 (boston, ...)，來訓練自己的線性迴歸模型，並加上適當的正則話來觀察訓練情形。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine=datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine=pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "print(df_wine.shape)\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "5      14.20        1.76  2.45               15.2      112.0           3.27   \n",
       "6      14.39        1.87  2.45               14.6       96.0           2.50   \n",
       "7      14.06        2.15  2.61               17.6      121.0           2.60   \n",
       "8      14.83        1.64  2.17               14.0       97.0           2.80   \n",
       "9      13.86        1.35  2.27               16.0       98.0           2.98   \n",
       "10     14.10        2.16  2.30               18.0      105.0           2.95   \n",
       "11     14.12        1.48  2.32               16.8       95.0           2.20   \n",
       "12     13.75        1.73  2.41               16.0       89.0           2.60   \n",
       "13     14.75        1.73  2.39               11.4       91.0           3.10   \n",
       "14     14.38        1.87  2.38               12.0      102.0           3.30   \n",
       "15     13.63        1.81  2.70               17.2      112.0           2.85   \n",
       "16     14.30        1.92  2.72               20.0      120.0           2.80   \n",
       "17     13.83        1.57  2.62               20.0      115.0           2.95   \n",
       "18     14.19        1.59  2.48               16.5      108.0           3.30   \n",
       "19     13.64        3.10  2.56               15.2      116.0           2.70   \n",
       "20     14.06        1.63  2.28               16.0      126.0           3.00   \n",
       "21     12.93        3.80  2.65               18.6      102.0           2.41   \n",
       "22     13.71        1.86  2.36               16.6      101.0           2.61   \n",
       "23     12.85        1.60  2.52               17.8       95.0           2.48   \n",
       "24     13.50        1.81  2.61               20.0       96.0           2.53   \n",
       "25     13.05        2.05  3.22               25.0      124.0           2.63   \n",
       "26     13.39        1.77  2.62               16.1       93.0           2.85   \n",
       "27     13.30        1.72  2.14               17.0       94.0           2.40   \n",
       "28     13.87        1.90  2.80               19.4      107.0           2.95   \n",
       "29     14.02        1.68  2.21               16.0       96.0           2.65   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "148    13.32        3.24  2.38               21.5       92.0           1.93   \n",
       "149    13.08        3.90  2.36               21.5      113.0           1.41   \n",
       "150    13.50        3.12  2.62               24.0      123.0           1.40   \n",
       "151    12.79        2.67  2.48               22.0      112.0           1.48   \n",
       "152    13.11        1.90  2.75               25.5      116.0           2.20   \n",
       "153    13.23        3.30  2.28               18.5       98.0           1.80   \n",
       "154    12.58        1.29  2.10               20.0      103.0           1.48   \n",
       "155    13.17        5.19  2.32               22.0       93.0           1.74   \n",
       "156    13.84        4.12  2.38               19.5       89.0           1.80   \n",
       "157    12.45        3.03  2.64               27.0       97.0           1.90   \n",
       "158    14.34        1.68  2.70               25.0       98.0           2.80   \n",
       "159    13.48        1.67  2.64               22.5       89.0           2.60   \n",
       "160    12.36        3.83  2.38               21.0       88.0           2.30   \n",
       "161    13.69        3.26  2.54               20.0      107.0           1.83   \n",
       "162    12.85        3.27  2.58               22.0      106.0           1.65   \n",
       "163    12.96        3.45  2.35               18.5      106.0           1.39   \n",
       "164    13.78        2.76  2.30               22.0       90.0           1.35   \n",
       "165    13.73        4.36  2.26               22.5       88.0           1.28   \n",
       "166    13.45        3.70  2.60               23.0      111.0           1.70   \n",
       "167    12.82        3.37  2.30               19.5       88.0           1.48   \n",
       "168    13.58        2.58  2.69               24.5      105.0           1.55   \n",
       "169    13.40        4.60  2.86               25.0      112.0           1.98   \n",
       "170    12.20        3.03  2.32               19.0       96.0           1.25   \n",
       "171    12.77        2.39  2.28               19.5       86.0           1.39   \n",
       "172    14.16        2.51  2.48               20.0       91.0           1.68   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29         5.640000  1.04   \n",
       "1          2.76                  0.26             1.28         4.380000  1.05   \n",
       "2          3.24                  0.30             2.81         5.680000  1.03   \n",
       "3          3.49                  0.24             2.18         7.800000  0.86   \n",
       "4          2.69                  0.39             1.82         4.320000  1.04   \n",
       "5          3.39                  0.34             1.97         6.750000  1.05   \n",
       "6          2.52                  0.30             1.98         5.250000  1.02   \n",
       "7          2.51                  0.31             1.25         5.050000  1.06   \n",
       "8          2.98                  0.29             1.98         5.200000  1.08   \n",
       "9          3.15                  0.22             1.85         7.220000  1.01   \n",
       "10         3.32                  0.22             2.38         5.750000  1.25   \n",
       "11         2.43                  0.26             1.57         5.000000  1.17   \n",
       "12         2.76                  0.29             1.81         5.600000  1.15   \n",
       "13         3.69                  0.43             2.81         5.400000  1.25   \n",
       "14         3.64                  0.29             2.96         7.500000  1.20   \n",
       "15         2.91                  0.30             1.46         7.300000  1.28   \n",
       "16         3.14                  0.33             1.97         6.200000  1.07   \n",
       "17         3.40                  0.40             1.72         6.600000  1.13   \n",
       "18         3.93                  0.32             1.86         8.700000  1.23   \n",
       "19         3.03                  0.17             1.66         5.100000  0.96   \n",
       "20         3.17                  0.24             2.10         5.650000  1.09   \n",
       "21         2.41                  0.25             1.98         4.500000  1.03   \n",
       "22         2.88                  0.27             1.69         3.800000  1.11   \n",
       "23         2.37                  0.26             1.46         3.930000  1.09   \n",
       "24         2.61                  0.28             1.66         3.520000  1.12   \n",
       "25         2.68                  0.47             1.92         3.580000  1.13   \n",
       "26         2.94                  0.34             1.45         4.800000  0.92   \n",
       "27         2.19                  0.27             1.35         3.950000  1.02   \n",
       "28         2.97                  0.37             1.76         4.500000  1.25   \n",
       "29         2.33                  0.26             1.98         4.700000  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "148        0.76                  0.45             1.25         8.420000  0.55   \n",
       "149        1.39                  0.34             1.14         9.400000  0.57   \n",
       "150        1.57                  0.22             1.25         8.600000  0.59   \n",
       "151        1.36                  0.24             1.26        10.800000  0.48   \n",
       "152        1.28                  0.26             1.56         7.100000  0.61   \n",
       "153        0.83                  0.61             1.87        10.520000  0.56   \n",
       "154        0.58                  0.53             1.40         7.600000  0.58   \n",
       "155        0.63                  0.61             1.55         7.900000  0.60   \n",
       "156        0.83                  0.48             1.56         9.010000  0.57   \n",
       "157        0.58                  0.63             1.14         7.500000  0.67   \n",
       "158        1.31                  0.53             2.70        13.000000  0.57   \n",
       "159        1.10                  0.52             2.29        11.750000  0.57   \n",
       "160        0.92                  0.50             1.04         7.650000  0.56   \n",
       "161        0.56                  0.50             0.80         5.880000  0.96   \n",
       "162        0.60                  0.60             0.96         5.580000  0.87   \n",
       "163        0.70                  0.40             0.94         5.280000  0.68   \n",
       "164        0.68                  0.41             1.03         9.580000  0.70   \n",
       "165        0.47                  0.52             1.15         6.620000  0.78   \n",
       "166        0.92                  0.43             1.46        10.680000  0.85   \n",
       "167        0.66                  0.40             0.97        10.260000  0.72   \n",
       "168        0.84                  0.39             1.54         8.660000  0.74   \n",
       "169        0.96                  0.27             1.11         8.500000  0.67   \n",
       "170        0.49                  0.40             0.73         5.500000  0.66   \n",
       "171        0.51                  0.48             0.64         9.899999  0.57   \n",
       "172        0.70                  0.44             1.24         9.700000  0.62   \n",
       "173        0.61                  0.52             1.06         7.700000  0.64   \n",
       "174        0.75                  0.43             1.41         7.300000  0.70   \n",
       "175        0.69                  0.43             1.35        10.200000  0.59   \n",
       "176        0.68                  0.53             1.46         9.300000  0.60   \n",
       "177        0.76                  0.56             1.35         9.200000  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "5                            2.85   1450.0  \n",
       "6                            3.58   1290.0  \n",
       "7                            3.58   1295.0  \n",
       "8                            2.85   1045.0  \n",
       "9                            3.55   1045.0  \n",
       "10                           3.17   1510.0  \n",
       "11                           2.82   1280.0  \n",
       "12                           2.90   1320.0  \n",
       "13                           2.73   1150.0  \n",
       "14                           3.00   1547.0  \n",
       "15                           2.88   1310.0  \n",
       "16                           2.65   1280.0  \n",
       "17                           2.57   1130.0  \n",
       "18                           2.82   1680.0  \n",
       "19                           3.36    845.0  \n",
       "20                           3.71    780.0  \n",
       "21                           3.52    770.0  \n",
       "22                           4.00   1035.0  \n",
       "23                           3.63   1015.0  \n",
       "24                           3.82    845.0  \n",
       "25                           3.20    830.0  \n",
       "26                           3.22   1195.0  \n",
       "27                           2.77   1285.0  \n",
       "28                           3.40    915.0  \n",
       "29                           3.59   1035.0  \n",
       "..                            ...      ...  \n",
       "148                          1.62    650.0  \n",
       "149                          1.33    550.0  \n",
       "150                          1.30    500.0  \n",
       "151                          1.47    480.0  \n",
       "152                          1.33    425.0  \n",
       "153                          1.51    675.0  \n",
       "154                          1.55    640.0  \n",
       "155                          1.48    725.0  \n",
       "156                          1.64    480.0  \n",
       "157                          1.73    880.0  \n",
       "158                          1.96    660.0  \n",
       "159                          1.78    620.0  \n",
       "160                          1.58    520.0  \n",
       "161                          1.82    680.0  \n",
       "162                          2.11    570.0  \n",
       "163                          1.75    675.0  \n",
       "164                          1.68    615.0  \n",
       "165                          1.75    520.0  \n",
       "166                          1.56    695.0  \n",
       "167                          1.75    685.0  \n",
       "168                          1.80    750.0  \n",
       "169                          1.92    630.0  \n",
       "170                          1.83    510.0  \n",
       "171                          1.63    470.0  \n",
       "172                          1.71    660.0  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(wine.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "logr = linear_model.LogisticRegression()\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "logr.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = logr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [[-6.82864779e-01  7.19709566e-01  9.78123238e-01 -5.71326897e-01\n",
      "  -3.15688084e-02  3.00522775e-01  1.11716506e+00 -3.43549778e-02\n",
      "  -4.90150215e-01 -1.05374113e-02 -1.54185796e-01  9.61331414e-01\n",
      "   1.81479366e-02]\n",
      " [ 9.32405991e-01 -1.02836307e+00 -7.03687526e-01  2.35034368e-01\n",
      "   8.51406104e-03  7.62359762e-02  4.71638459e-01  5.60638803e-01\n",
      "   6.15085511e-01 -1.81947987e+00  9.33098198e-01  7.36442197e-02\n",
      "  -1.40242413e-02]\n",
      " [-4.72180741e-01  6.31034394e-01 -6.36847579e-02  1.56380289e-01\n",
      "   3.13408128e-02 -7.52374558e-01 -1.62587954e+00 -1.31786834e-01\n",
      "  -7.01391158e-01  1.03384290e+00 -4.87953685e-01 -1.15357424e+00\n",
      "   1.40302540e-04]]\n",
      "Mean squared error: 0.03\n"
     ]
    }
   ],
   "source": [
    "# 可以看回歸模型的參數值\n",
    "print('Coefficients: ', logr.coef_)\n",
    "\n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "lasso = linear_model.Lasso(alpha=1.0)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO alpha=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [ 0.          0.          0.          0.          0.         -0.\n",
      " -0.          0.         -0.          0.         -0.         -0.\n",
      " -0.00159714]\n",
      "Mean squared error: 0.42\n"
     ]
    }
   ],
   "source": [
    "# 可以看回歸模型的參數值\n",
    "print('Coefficients: ', lasso.coef_)\n",
    "\n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO alpha=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立一個線性回歸模型\n",
    "lasso = linear_model.Lasso(alpha=0.6)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [ 0.          0.          0.          0.          0.         -0.\n",
      " -0.          0.         -0.          0.0410511  -0.         -0.\n",
      " -0.00169201]\n",
      "Mean squared error: 0.35\n"
     ]
    }
   ],
   "source": [
    "# 可以看回歸模型的參數值\n",
    "print('Coefficients: ', lasso.coef_)\n",
    "\n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge alpha=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "ridge = linear_model.Ridge(alpha=1.0)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [-0.1060308   0.01767173 -0.20185208  0.04519307  0.00041456  0.09901609\n",
      " -0.31237143 -0.1038379   0.03489971  0.07770768 -0.13450626 -0.27442063\n",
      " -0.00077001]\n",
      "Mean squared error: 0.07\n"
     ]
    }
   ],
   "source": [
    "# 可以看回歸模型的參數值\n",
    "print('Coefficients: ', ridge.coef_)\n",
    "\n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge alpha=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立一個線性回歸模型\n",
    "ridge = linear_model.Ridge(alpha=0.3)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [-0.10795612  0.01693011 -0.21462782  0.04620941  0.0003719   0.1158287\n",
      " -0.32107587 -0.15292041  0.03635502  0.07633175 -0.1497215  -0.28189725\n",
      " -0.00075737]\n",
      "Mean squared error: 0.07\n"
     ]
    }
   ],
   "source": [
    "# 可以看回歸模型的參數值\n",
    "print('Coefficients: ', ridge.coef_)\n",
    "\n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
